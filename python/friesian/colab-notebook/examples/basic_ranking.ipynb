{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274aee66",
   "metadata": {},
   "source": [
    "![](../../../image/colab_logo_32px.png)[Run in Google Colab](https://colab.research.google.com/github/intel-analytics/analytics-zoo/blob/master/docs/docs/colab-notebook/friesian/examples/basic_ranking.ipynb) &nbsp;![](../../../image/GitHub-Mark-32px.png)[View source on GitHub](https://github.com/intel-analytics/analytics-zoo/blob/master/docs/docs/colab-notebook/friesian/examples/basic_ranking.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright 2016 The BigDL Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "#\n",
    "# Copyright 2020 The TensorFlow Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "# This example is based on Tensorflow Recommenders example [basic ranking](https://www.tensorflow.org/recommenders/examples/basic_ranking).\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f54e58",
   "metadata": {},
   "source": [
    "# Basic Ranking Example\n",
    "\n",
    "In this tutorial, we're going to:\n",
    "\n",
    "1. Use Friesian FeatureTable to get and preprocess the movielens data and split it into a training and test set.\n",
    "2. Convert the preprocessed FeatureTable to an Orca TF Dataset and do some further data preprocessing.\n",
    "3. Fit and evaluate the TFRS ranking model using Orca TF Estimator and Orca TF Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13814b7c",
   "metadata": {},
   "source": [
    "# Environment Preparation\n",
    "\n",
    "### Install Java 8\n",
    "\n",
    "Run the cell on the **Google Colab** to install jdk 1.8.\n",
    "\n",
    "**Note**: if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install jdk8\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "import os\n",
    "# Set environment variable JAVA_HOME.\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb932bf",
   "metadata": {},
   "source": [
    "### Install BigDL Friesian\n",
    "\n",
    "You can install the latest pre-release version using pip install --pre --upgrade bigdl-friesian[train]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753278fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting bigdl-friesian[train]\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/62/d026698fa78f206dd3ac15a6f248a7cfcaff87471e22412d6ed364532eba/bigdl_friesian-2.1.0b20220612-py3-none-macosx_10_11_x86_64.whl (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 213 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bigdl-orca==2.1.0b20220612\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5c/2b/e998effe89061fc9a8f76363df8ec0fa53871bff28127e0c12c6604cd544/bigdl_orca-2.1.0b20220612-py3-none-macosx_10_11_x86_64.whl (28.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.0 MB 1.1 MB/s eta 0:00:01     |████████████████▌               | 14.4 MB 685 kB/s eta 0:00:20\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyzmq in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (22.3.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: bigdl-math==0.14.0.dev1 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (0.14.0.dev1)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: bigdl-tf==0.14.0.dev1 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (0.14.0.dev1)\n",
      "Collecting bigdl-dllib==2.1.0b20220612\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fd/9b/9cb4bd4ec2812db50e7a01a0801ab7a86c51cea287621c6540a25eef45a0/bigdl_dllib-2.1.0b20220612-py3-none-macosx_10_11_x86_64.whl (51.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 51.8 MB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing!=3.0.5,>=2.0.2 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from packaging->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: bigdl-core==2.1.0b20220321 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (2.1.0b20220321)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.19.5 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (1.21.6)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: conda-pack==0.3.1 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pyspark==2.4.6 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from conda-pack==0.3.1->bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (47.3.1.post20200622)\n",
      "Requirement already satisfied, skipping upgrade: py4j==0.10.7 in /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages (from pyspark==2.4.6->bigdl-dllib==2.1.0b20220612->bigdl-orca==2.1.0b20220612->bigdl-friesian[train]) (0.10.7)\n",
      "Installing collected packages: bigdl-dllib, bigdl-orca, bigdl-friesian\n",
      "  Attempting uninstall: bigdl-dllib\n",
      "    Found existing installation: bigdl-dllib 2.1.0b20220609\n",
      "    Uninstalling bigdl-dllib-2.1.0b20220609:\n",
      "      Successfully uninstalled bigdl-dllib-2.1.0b20220609\n",
      "  Attempting uninstall: bigdl-orca\n",
      "    Found existing installation: bigdl-orca 2.1.0b20220609\n",
      "    Uninstalling bigdl-orca-2.1.0b20220609:\n",
      "      Successfully uninstalled bigdl-orca-2.1.0b20220609\n",
      "  Attempting uninstall: bigdl-friesian\n",
      "    Found existing installation: bigdl-friesian 2.1.0b20220609\n",
      "    Uninstalling bigdl-friesian-2.1.0b20220609:\n",
      "      Successfully uninstalled bigdl-friesian-2.1.0b20220609\n",
      "Successfully installed bigdl-dllib-2.1.0b20220612 bigdl-friesian-2.1.0b20220612 bigdl-orca-2.1.0b20220612\n"
     ]
    }
   ],
   "source": [
    "# Install latest pre-release version of BigDL Friesian \n",
    "# Installing BigDL Friesian from pip will automatically install pyspark and their dependencies.\n",
    "!pip install --pre --upgrade bigdl-friesian[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install tensorflow tensorflow-recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf1b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b24e",
   "metadata": {},
   "source": [
    "## Distributed TFRS using Orca and Friesian APIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from bigdl.friesian.models import TFRSModel\n",
    "from bigdl.orca import init_orca_context, stop_orca_context\n",
    "from bigdl.orca import OrcaContext\n",
    "from bigdl.friesian.feature import FeatureTable\n",
    "from bigdl.orca.learn.tf2 import Estimator\n",
    "from bigdl.orca.data.tf.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a49009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing orca context\n",
      "Current pyspark location is : /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages/pyspark/__init__.py\n",
      "Start to getOrCreate SparkContext\n",
      "pyspark_submit_args is:  --driver-class-path /Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/core/lib/all-2.1.0-20220314.094552-2.jar:/Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/friesian/lib/bigdl-friesian-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/Users/yita/anaconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
      "2022-06-13 20:30:25 WARN  Utils:66 - Your hostname, chenyinadeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.104 instead (on interface en0)\n",
      "2022-06-13 20:30:25 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2022-06-13 20:30:56 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 20:31:01,170 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2022-06-13 20:31:01,173 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2022-06-13 20:31:01,174 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2022-06-13 20:31:01,175 Thread-3 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "22-06-13 20:31:01 [Thread-3] INFO  Engine$:121 - Auto detect executor number and executor cores number\n",
      "22-06-13 20:31:01 [Thread-3] INFO  Engine$:123 - Executor number is 1 and executor cores number is 1\n",
      "22-06-13 20:31:02 [Thread-3] INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 14\n",
      "2022-06-13 20:31:02 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.\n",
      "22-06-13 20:31:02 [Thread-3] INFO  Engine$:456 - Find existing spark context. Checking the spark conf...\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.Sample\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  Sample\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.EvaluatedResult\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  EvaluatedResult\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JTensor\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  JTensor\n",
      "Successfully got a SparkContext\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JActivity\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  JActivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=1\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=0\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=0\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='1'\n",
      "   OMP_PROC_BIND='false'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recommended to set it to True when running BigDL in Jupyter notebook. \n",
    "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "\n",
    "if cluster_mode == \"local\":\n",
    "    init_orca_context(cores=1, memory=\"4g\") # run in local mode\n",
    "elif cluster_mode == \"k8s\":\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
    "elif cluster_mode == \"yarn\":\n",
    "    init_orca_context(\n",
    "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
    "        driver_memory=\"10g\", driver_cores=1\n",
    "        ) # run on Hadoop YARN cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae770ac",
   "metadata": {},
   "source": [
    "This is the only place where you need to specify local or distributed mode. View Orca Context for more details.\n",
    "\n",
    "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a1fa9",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7ae843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleRankingModel(tfrs.models.Model):\n",
    "    def __init__(self, user_id_num, movie_title_num):\n",
    "        super().__init__()\n",
    "        embedding_dim = 32\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(user_id_num + 1, embedding_dim)\n",
    "        self.movie_embedding = tf.keras.layers.Embedding(movie_title_num + 1, embedding_dim)\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "              # Learn multiple dense layers.\n",
    "              tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "              tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "              # Make rating predictions in the final layer.\n",
    "              tf.keras.layers.Dense(1)\n",
    "          ])\n",
    "\n",
    "    def call(self, features):\n",
    "        embeddings = tf.concat([self.user_embedding(features[\"user_id\"]),\n",
    "                               self.movie_embedding(features[\"movie_title\"])], axis=1)\n",
    "        return self.ratings(embeddings)\n",
    "\n",
    "    def compute_loss(self, inputs, training: bool = False) -> tf.Tensor:\n",
    "        labels = inputs[\"user_rating\"]\n",
    "        rating_predictions = self(inputs)\n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07f376",
   "metadata": {},
   "source": [
    "### Define the dataset\n",
    "\n",
    "Use Friesian FeatureTable to get and preprocess the movielens data and split it into a training and test set.\n",
    "\n",
    "First, we will download the [ml-1m dataset](https://grouplens.org/datasets/movielens/1m/) and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddac09f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip && unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./ml-1m/\"\n",
    "\n",
    "# UserID::MovieID::Rating::Timestamp\n",
    "# UserID::Gender::Age::Occupation::Zip-code\n",
    "# MovieID::Title::Genres\n",
    "dataset = {\n",
    "    \"ratings\": ['userid', 'movieid', 'rating', 'timestamp'],\n",
    "    \"movies\": [\"movieid\", \"title\", \"genres\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda96a16",
   "metadata": {},
   "source": [
    "Then we will use Friesian FeatureTable to read the .dat files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_dict = dict()\n",
    "for data, cols in dataset.items():\n",
    "    tbl = FeatureTable.read_csv(os.path.join(data_dir, data + \".dat\"),\n",
    "                                delimiter=\":\", header=False)\n",
    "    tmp_cols = tbl.columns[::2]\n",
    "    tbl = tbl.select(tmp_cols)\n",
    "    col_dict = {c[0]: c[1] for c in zip(tmp_cols, cols)}\n",
    "    tbl = tbl.rename(col_dict)\n",
    "    tbl_dict[data] = tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700844de",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tbl = tbl_dict[\"ratings\"].join(tbl_dict[\"movies\"], \"movieid\")\\\n",
    "    .dropna(columns=None).select([\"userid\", \"title\", \"rating\"])\n",
    "full_tbl = full_tbl.cast([\"rating\"], \"int\")\n",
    "full_tbl = full_tbl.cast([\"userid\"], \"string\")\n",
    "full_tbl.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f1690",
   "metadata": {},
   "source": [
    "Generate unique index value of categorical features and encode these columns with generated string indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_idx = full_tbl.gen_string_idx([\"userid\", \"title\"])\n",
    "user_id_size = str_idx[0].size()\n",
    "title_size = str_idx[1].size()\n",
    "full_tbl = full_tbl.encode_string([\"userid\", \"title\"], str_idx)\n",
    "full_tbl.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855f111",
   "metadata": {},
   "source": [
    "Sample 10% data and split it into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_tbl = full_tbl.sample(0.1, seed=42)\n",
    "train_tbl, test_tbl = part_tbl.random_split([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2039efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = train_tbl.size()\n",
    "steps = math.ceil(train_count / 8192)\n",
    "print(\"train size: \", train_count, \", steps: \", steps)\n",
    "\n",
    "test_count = test_tbl.size()\n",
    "test_steps = math.ceil(test_count / 4096)\n",
    "print(\"test size: \", test_count, \", steps: \", test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99592e2f",
   "metadata": {},
   "source": [
    "Create Orca TF Datasets from a Friesian FeatureTables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2545ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_feature_table(train_tbl)\n",
    "test_ds = Dataset.from_feature_table(test_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12ae5d",
   "metadata": {},
   "source": [
    "Once the Orca TF Dataset is created, we can perform some data preprocessing using the map function. Since the model use `input[\"movie_title\"], input[\"user_id\"] and input[\"user_rating\"]` in the model `call` and `compute_loss` function, we should change the key name of the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x: {\n",
    "    \"movie_title\": x[\"title\"],\n",
    "    \"user_id\": x[\"userid\"],\n",
    "    \"user_rating\": x[\"rating\"],\n",
    "})\n",
    "test_ds = test_ds.map(lambda x: {\n",
    "    \"movie_title\": x[\"title\"],\n",
    "    \"user_id\": x[\"userid\"],\n",
    "    \"user_rating\": x[\"rating\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dbdf2",
   "metadata": {},
   "source": [
    "Create an Orca Estimator using the SampleRankingModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(config):\n",
    "    model = SampleRankingModel(user_id_num=user_id_size, movie_title_num=title_size)\n",
    "    model = TFRSModel(model)\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.keras.optimizers.Adagrad(config[\"lr\"]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 0.1\n",
    "}\n",
    "\n",
    "est = Estimator.from_keras(model_creator=model_creator,\n",
    "                           verbose=True,\n",
    "                           config=config, backend=\"tf2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ac590",
   "metadata": {},
   "source": [
    "Then train the model using Orca TF Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(train_ds, 3, batch_size=8192, steps_per_epoch=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6a20f",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54082660",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.evaluate(test_ds, 4096, num_steps=test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be61891",
   "metadata": {},
   "source": [
    "Shutdown the Estimator and stop the orca context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8995583",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.shutdown()\n",
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
